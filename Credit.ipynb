{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feature_engine in c:\\python312\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\python312\\lib\\site-packages (from feature_engine) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.2.0 in c:\\python312\\lib\\site-packages (from feature_engine) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.4.0 in c:\\python312\\lib\\site-packages (from feature_engine) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\python312\\lib\\site-packages (from feature_engine) (1.13.0)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in c:\\python312\\lib\\site-packages (from feature_engine) (0.14.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aomid\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=2.2.0->feature_engine) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas>=2.2.0->feature_engine) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas>=2.2.0->feature_engine) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python312\\lib\\site-packages (from scikit-learn>=1.4.0->feature_engine) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python312\\lib\\site-packages (from scikit-learn>=1.4.0->feature_engine) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\python312\\lib\\site-packages (from statsmodels>=0.11.1->feature_engine) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\aomid\\appdata\\roaming\\python\\python312\\site-packages (from statsmodels>=0.11.1->feature_engine) (24.0)\n",
      "Requirement already satisfied: six in c:\\python312\\lib\\site-packages (from patsy>=0.5.6->statsmodels>=0.11.1->feature_engine) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import lightningchart as lc\n",
    "import random\n",
    "lc.set_license('my-license-key')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, StackingClassifier\n",
    "from scipy.stats import probplot\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.selection import DropConstantFeatures, DropDuplicateFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from collections import Counter\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "import warnings, gc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "gc.enable()  # Enabling garbage collection to manage memory during large data operations.\n",
    "\n",
    "# Ensuring to install feature_engine correctly.\n",
    "!pip install feature_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>59000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>123.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>D</td>\n",
       "      <td>35000</td>\n",
       "      <td>16.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9600</td>\n",
       "      <td>OWN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>1000</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>9600</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>5500</td>\n",
       "      <td>12.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>65500</td>\n",
       "      <td>RENT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>35000</td>\n",
       "      <td>15.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>54400</td>\n",
       "      <td>RENT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>35000</td>\n",
       "      <td>14.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.55</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0          22          59000                  RENT              123.0   \n",
       "1          21           9600                   OWN                5.0   \n",
       "2          25           9600              MORTGAGE                1.0   \n",
       "3          23          65500                  RENT                4.0   \n",
       "4          24          54400                  RENT                8.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
       "0    PERSONAL          D      35000          16.02            1   \n",
       "1   EDUCATION          B       1000          11.14            0   \n",
       "2     MEDICAL          C       5500          12.87            1   \n",
       "3     MEDICAL          C      35000          15.23            1   \n",
       "4     MEDICAL          C      35000          14.27            1   \n",
       "\n",
       "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "0                 0.59                         Y                           3  \n",
       "1                 0.10                         N                           2  \n",
       "2                 0.57                         N                           3  \n",
       "3                 0.53                         N                           2  \n",
       "4                 0.55                         Y                           4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "data = pd.read_csv(\"./credit_risk_dataset.csv\")\n",
    "df=data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_age                    0\n",
       "person_income                 0\n",
       "person_home_ownership         0\n",
       "person_emp_length             0\n",
       "loan_intent                   0\n",
       "loan_grade                    0\n",
       "loan_amnt                     0\n",
       "loan_int_rate                 0\n",
       "loan_status                   0\n",
       "loan_percent_income           0\n",
       "cb_person_default_on_file     0\n",
       "cb_person_cred_hist_length    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removimg duplicate and handling missing data\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 28501\n",
      "Variables: 12\n",
      "cat_cols: 5\n",
      "num_cols: 7\n",
      "cat_but_car: 0\n",
      "num_but_cat: 1\n"
     ]
    }
   ],
   "source": [
    "# Initial classification based on data type\n",
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
    "                dataframe[col].dtypes != \"O\"]\n",
    "\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
    "                dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    # Updating categorical columns list\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    # Defining numerical columns excluding numeric but categorical\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "\n",
    "    print(f\"Observations: {dataframe.shape[0]}\")\n",
    "    print(f\"Variables: {dataframe.shape[1]}\")\n",
    "    print(f'cat_cols: {len(cat_cols)}')\n",
    "    print(f'num_cols: {len(num_cols)}')\n",
    "    print(f'cat_but_car: {len(cat_but_car)}')\n",
    "    print(f'num_but_cat: {len(num_but_cat)}')\n",
    "    return cat_cols, cat_but_car, num_cols\n",
    "\n",
    "cat_cols, cat_but_car, num_cols = grab_col_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>person_age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178987</td>\n",
       "      <td>0.165624</td>\n",
       "      <td>0.054246</td>\n",
       "      <td>0.010170</td>\n",
       "      <td>0.024091</td>\n",
       "      <td>0.040782</td>\n",
       "      <td>0.859621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_income</th>\n",
       "      <td>0.178987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136427</td>\n",
       "      <td>0.264942</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.140456</td>\n",
       "      <td>0.251487</td>\n",
       "      <td>0.116622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_emp_length</th>\n",
       "      <td>0.165624</td>\n",
       "      <td>0.136427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110934</td>\n",
       "      <td>0.056607</td>\n",
       "      <td>0.082852</td>\n",
       "      <td>0.055033</td>\n",
       "      <td>0.146486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0.054246</td>\n",
       "      <td>0.264942</td>\n",
       "      <td>0.110934</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146026</td>\n",
       "      <td>0.114153</td>\n",
       "      <td>0.577708</td>\n",
       "      <td>0.045334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_int_rate</th>\n",
       "      <td>0.010170</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.056607</td>\n",
       "      <td>0.146026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.339995</td>\n",
       "      <td>0.123441</td>\n",
       "      <td>0.014562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>0.024091</td>\n",
       "      <td>0.140456</td>\n",
       "      <td>0.082852</td>\n",
       "      <td>0.114153</td>\n",
       "      <td>0.339995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.016559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_percent_income</th>\n",
       "      <td>0.040782</td>\n",
       "      <td>0.251487</td>\n",
       "      <td>0.055033</td>\n",
       "      <td>0.577708</td>\n",
       "      <td>0.123441</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <td>0.859621</td>\n",
       "      <td>0.116622</td>\n",
       "      <td>0.146486</td>\n",
       "      <td>0.045334</td>\n",
       "      <td>0.014562</td>\n",
       "      <td>0.016559</td>\n",
       "      <td>0.029690</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            person_age  person_income  person_emp_length  \\\n",
       "person_age                    1.000000       0.178987           0.165624   \n",
       "person_income                 0.178987       1.000000           0.136427   \n",
       "person_emp_length             0.165624       0.136427           1.000000   \n",
       "loan_amnt                     0.054246       0.264942           0.110934   \n",
       "loan_int_rate                 0.010170       0.001346           0.056607   \n",
       "loan_status                   0.024091       0.140456           0.082852   \n",
       "loan_percent_income           0.040782       0.251487           0.055033   \n",
       "cb_person_cred_hist_length    0.859621       0.116622           0.146486   \n",
       "\n",
       "                            loan_amnt  loan_int_rate  loan_status  \\\n",
       "person_age                   0.054246       0.010170     0.024091   \n",
       "person_income                0.264942       0.001346     0.140456   \n",
       "person_emp_length            0.110934       0.056607     0.082852   \n",
       "loan_amnt                    1.000000       0.146026     0.114153   \n",
       "loan_int_rate                0.146026       1.000000     0.339995   \n",
       "loan_status                  0.114153       0.339995     1.000000   \n",
       "loan_percent_income          0.577708       0.123441     0.380000   \n",
       "cb_person_cred_hist_length   0.045334       0.014562     0.016559   \n",
       "\n",
       "                            loan_percent_income  cb_person_cred_hist_length  \n",
       "person_age                             0.040782                    0.859621  \n",
       "person_income                          0.251487                    0.116622  \n",
       "person_emp_length                      0.055033                    0.146486  \n",
       "loan_amnt                              0.577708                    0.045334  \n",
       "loan_int_rate                          0.123441                    0.014562  \n",
       "loan_status                            0.380000                    0.016559  \n",
       "loan_percent_income                    1.000000                    0.029690  \n",
       "cb_person_cred_hist_length             0.029690                    1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def high_correlated_cols(dataframe, display_table=False, corr_th=0.70):\n",
    "    # Selecting only the numeric columns from the DataFrame\n",
    "    numeric_dataframe = dataframe.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Calculating the absolute correlation matrix\n",
    "    corr = numeric_dataframe.corr().abs()\n",
    "    \n",
    "    # Create an upper triangle matrix to identify high correlations\n",
    "    upper_triangle_matrix = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n",
    "    \n",
    "    if display_table:\n",
    "        # Displaying the correlation matrix\n",
    "        print(\"Correlation Matrix:\")\n",
    "        display(corr)  # This uses IPython.display.display to show the DataFrame in Jupyter\n",
    "        \n",
    "    return drop_list\n",
    "\n",
    "drop_list = high_correlated_cols(df, display_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:54949\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556d443da0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing data for the PieChart\n",
    "target = df.loan_status.value_counts(normalize=True) * 100\n",
    "target.rename(index={1: 'Default', 0: 'Non-default'}, inplace=True)\n",
    "\n",
    "# Initializing and configuring the PieChart\n",
    "chart = lc.PieChart(\n",
    "    labels_inside_slices=False,\n",
    "    title='Target Distribution',\n",
    "    theme=lc.Themes.White\n",
    ")\n",
    "\n",
    "# Adding a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "\n",
    "# Adding slices to the chart\n",
    "for label, value in target.items():\n",
    "    pie_slice = chart.add_slice(label, value)\n",
    "\n",
    "# Adding the entire chart\n",
    "legend.add(chart)\n",
    "\n",
    "# Setting an inner radius to create a donut-like appearance\n",
    "chart.set_inner_radius(50)\n",
    "\n",
    "# Opening the chart window\n",
    "chart.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_age True\n",
      "person_income True\n",
      "person_emp_length True\n",
      "loan_amnt False\n",
      "loan_int_rate False\n",
      "loan_percent_income True\n",
      "cb_person_cred_hist_length True\n"
     ]
    }
   ],
   "source": [
    "# Calculating the quantiles at specified levels\n",
    "def outlier_thresholds(dataframe, variable, low_quantile=0.10, up_quantile=0.90):\n",
    "    quantile_one = dataframe[variable].quantile(low_quantile)\n",
    "    quantile_three = dataframe[variable].quantile(up_quantile)\n",
    "    interquantile_range = quantile_three - quantile_one\n",
    "    up_limit = quantile_three + 1.5 * interquantile_range\n",
    "    low_limit = quantile_one - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "# Obtaining the outlier thresholds\n",
    "def check_outlier(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "for col in num_cols:\n",
    "    if col != \"loan_status\":\n",
    "        print(col, check_outlier(df, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the lower and upper limits for outliers\n",
    "def replace_with_thresholds(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
    "\n",
    "\n",
    "for col in num_cols:\n",
    "    if col != \"loan_status\":\n",
    "        replace_with_thresholds(df,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:54950\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556d481280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing data for the Bar Chart\n",
    "# Adding age range\n",
    "bins = range(df['person_age'].min(), 80, 5) \n",
    "\n",
    "# Filtering data for good loan status\n",
    "df_good = df[df[\"loan_status\"] == 0]['person_age']\n",
    "\n",
    "# Defining bins\n",
    "bins = range(df['person_age'].min(), df['person_age'].max() + 2, 5)\n",
    "\n",
    "# Calculating histogram\n",
    "hist_good, bins_good = np.histogram(df_good, bins=bins)\n",
    "\n",
    "# Converting numpy array to Python list\n",
    "hist_good = hist_good.astype(int).tolist()\n",
    "\n",
    "# Creating a BarChart\n",
    "chart_good = lc.BarChart(vertical=True)\n",
    "chart_good.set_title(\"Good Loan Status Age Distribution\")\n",
    "\n",
    "# Filtering out categories and values with zero counts\n",
    "filtered_categories = []\n",
    "filtered_values = []\n",
    "\n",
    "for i in range(len(hist_good)):\n",
    "    if hist_good[i] > 0:\n",
    "        category_label = f\"{bins_good[i]}-{bins_good[i+1]}\"\n",
    "        filtered_categories.append(category_label)\n",
    "        filtered_values.append(hist_good[i])\n",
    "\n",
    "# Preparing data for the chart\n",
    "data_good = [{'category': filtered_categories[i], 'value': filtered_values[i]} for i in range(len(filtered_categories))]\n",
    "chart_good.set_data(data_good)\n",
    "\n",
    "# Opening the chart\n",
    "chart_good.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:54951\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556d481580>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing data for the Bar Chart\n",
    "# Adding age range\n",
    "df_filtered = df[df['person_age'] <= 80]\n",
    "\n",
    "# Filtering data for bad loan status\n",
    "df_bad = df[df[\"loan_status\"] == 1]['person_age']\n",
    "\n",
    "# Calculating histogram\n",
    "hist_bad, bins_bad = np.histogram(df_bad, bins=bins)\n",
    "\n",
    "# Converting numpy array to Python list\n",
    "hist_bad = hist_bad.astype(int).tolist()\n",
    "\n",
    "# Creating a BarChart\n",
    "chart_bad = lc.BarChart(vertical=True)\n",
    "chart_bad.set_title(\"Bad Loan Status Age Distribution\")\n",
    "\n",
    "# Adding bars to chart\n",
    "categories = [f\"{bins_bad[i]}-{bins_bad[i+1]}\" for i in range(len(bins_bad)-1)]\n",
    "values = [hist_bad[i] for i in range(len(hist_bad))]\n",
    "data_bad = [{'category': categories[i], 'value': values[i]} for i in range(len(categories))]\n",
    "chart_bad.set_data(data_bad)\n",
    "\n",
    "# Opening the chart\n",
    "chart_bad.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:54952\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556d4817f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing data for the Bar Chart\n",
    "# Adding age range\n",
    "df_filtered = df[df['person_age'] <= 80]\n",
    "\n",
    "# Recalculating the histogram:\n",
    "hist_filtered, bins_filtered = np.histogram(df_filtered['person_age'], bins=range(df_filtered['person_age'].min(), df_filtered['person_age'].max() + 5, 5))\n",
    "\n",
    "# excluding bins when displaying the histogram\n",
    "bins = range(df['person_age'].min(), 80, 5) \n",
    "hist_age, bins_age = np.histogram(df['person_age'], bins=bins)\n",
    "\n",
    "# Converting numpy array to Python list\n",
    "hist_age = hist_age.astype(int).tolist()\n",
    "\n",
    "# Creating a BarChart\n",
    "chart_age = lc.BarChart(vertical=True)\n",
    "chart_age.set_title(\"Overall Age Distribution\")\n",
    "\n",
    "# Adding bars to chart\n",
    "categories = [f\"{bins_age[i]}-{bins_age[i+1]}\" for i in range(len(bins_age)-1) if hist_age[i] > 0]\n",
    "values = [hist_age[i] for i in range(len(hist_age)) if hist_age[i] > 0]\n",
    "data_age = [{'category': categories[i], 'value': values[i]} for i in range(len(categories))]\n",
    "chart_age.set_data(data_age)\n",
    "\n",
    "# Opening the chart\n",
    "chart_age.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:54953\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556d483260>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing data for Stacked Bar Chart\n",
    "# Defining bins for age groups\n",
    "bins = range(df['person_age'].min(), df['person_age'].max() + 1, 5)\n",
    "\n",
    "# Histogram data preparation for three categories\n",
    "histograms = []\n",
    "categories = [f\"{bins[i]}-{bins[i+1]}\" for i in range(len(bins)-1)]\n",
    "\n",
    "# 'Good' loan status (Non-Default)\n",
    "df_good = df[df[\"loan_status\"] == 0]['person_age']\n",
    "hist_good, _ = np.histogram(df_good, bins=bins)\n",
    "hist_good = hist_good.astype(int).tolist()\n",
    "\n",
    "# 'Bad' loan status (Default)\n",
    "df_bad = df[df[\"loan_status\"] == 1]['person_age']\n",
    "hist_bad, _ = np.histogram(df_bad, bins=bins)\n",
    "hist_bad = hist_bad.astype(int).tolist()\n",
    "\n",
    "# 'Overall' loan status\n",
    "hist_overall, _ = np.histogram(df['person_age'], bins=bins)\n",
    "hist_overall = hist_overall.astype(int).tolist()\n",
    "\n",
    "# Creating a BarChart with stacked data using LightningChart\n",
    "chart = lc.BarChart(\n",
    "    vertical=True, \n",
    "    theme=lc.Themes.White, \n",
    "    title='Age Distribution by Loan Status'\n",
    ")\n",
    "chart.set_data_stacked(\n",
    "    categories,\n",
    "    [\n",
    "        {'subCategory': 'Good Loan Status', 'values': hist_good},\n",
    "        {'subCategory': 'Bad Loan Status', 'values': hist_bad},\n",
    "        {'subCategory': 'Overall Loan Status', 'values': hist_overall}\n",
    "    ]\n",
    ")\n",
    "chart.set_value_label_display_mode('hidden')\n",
    "chart.add_legend().add(chart)\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['MORTGAGE', 'OTHER', 'OWN', 'RENT']\n",
      "Loan Status = 0 Values: [10253, 66, 2029, 9965]\n",
      "Loan Status = 1 Values: [1483, 27, 145, 4533]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:54954\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556d4c8d70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing data for the Bar Chart\n",
    "# Calculating the counts for each home ownership category for each loan status\n",
    "home_ownership_counts = df.groupby(['person_home_ownership', 'loan_status']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensuring all categories are present for both loan statuses and fill missing ones with zero\n",
    "home_ownership_counts = home_ownership_counts.reindex(columns=[0, 1], fill_value=0)\n",
    "\n",
    "# Extracting categories and values\n",
    "categories = home_ownership_counts.index.tolist()\n",
    "loan_status_0_values = home_ownership_counts[0].tolist()  # Loan status = 0 counts\n",
    "loan_status_1_values = home_ownership_counts[1].tolist()  # Loan status = 1 counts\n",
    "\n",
    "# Printing the calculated values for verification\n",
    "print(\"Categories:\", categories)\n",
    "print(\"Loan Status = 0 Values:\", loan_status_0_values)\n",
    "print(\"Loan Status = 1 Values:\", loan_status_1_values)\n",
    "\n",
    "# Setting up the LightningChart environment\n",
    "chart = lc.BarChart(vertical=True)\n",
    "chart.set_title(\"Housing Distribution by Loan Status\")\n",
    "\n",
    "# Preparing grouped data\n",
    "grouped_data = [\n",
    "    {'name': 'Loan Status = Default', 'values': loan_status_1_values},\n",
    "    {'name': 'Loan Status = Non-default', 'values': loan_status_0_values}\n",
    "]\n",
    "\n",
    "# Setting grouped data on the chart\n",
    "chart.set_data_grouped(\n",
    "    categories,\n",
    "    [\n",
    "        {'subCategory': grouped_data[0]['name'], 'values': grouped_data[0]['values']},\n",
    "        {'subCategory': grouped_data[1]['name'], 'values': grouped_data[1]['values']}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Adding a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(chart)  \n",
    "\n",
    "# Opening the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan Grade Categories: ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
      "Loan Status = 1 Values: [898, 1448, 1155, 1921, 562, 146, 58]\n",
      "Loan Status = 0 Values: [8447, 7646, 4527, 1322, 307, 63, 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:54955\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556d4c9bb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing data for the Bar Chart\n",
    "# Calculating the counts for each loan grade category for each loan status\n",
    "loan_grade_counts = df.groupby(['loan_grade', 'loan_status']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensuring all categories are present for both loan statuses and fill missing ones with zero\n",
    "loan_grade_counts = loan_grade_counts.reindex(columns=[0, 1], fill_value=0)\n",
    "\n",
    "# Sorting the index to maintain a consistent order (A, B, C, ..., G)\n",
    "loan_grade_counts.sort_index(inplace=True)\n",
    "\n",
    "# Printing the calculated values for verification\n",
    "categories = loan_grade_counts.index.tolist()\n",
    "status_1_values = loan_grade_counts[1].tolist()  # Loan status = 1 counts\n",
    "status_0_values = loan_grade_counts[0].tolist()  # Loan status = 0 counts\n",
    "\n",
    "print(\"Loan Grade Categories:\", categories)\n",
    "print(\"Loan Status = 1 Values:\", status_1_values)\n",
    "print(\"Loan Status = 0 Values:\", status_0_values)\n",
    "\n",
    "# Setting up the LightningChart environment\n",
    "chart = lc.BarChart(vertical=True)\n",
    "chart.set_title(\"Loan Grade Distribution\")\n",
    "\n",
    "# Preparing grouped data\n",
    "grouped_data = [\n",
    "    {'name': 'Loan Status = Default', 'values': status_1_values},\n",
    "    {'name': 'Loan Status = Non-default', 'values': status_0_values}\n",
    "]\n",
    "\n",
    "# Setting grouped data on the chart\n",
    "chart.set_data_grouped(\n",
    "    categories,\n",
    "    [\n",
    "        {'subCategory': grouped_data[0]['name'], 'values': grouped_data[0]['values']},\n",
    "        {'subCategory': grouped_data[1]['name'], 'values': grouped_data[1]['values']},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Adding a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(chart)  \n",
    "\n",
    "# Opening the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan Intent Categories: ['DEBTCONSOLIDATION', 'EDUCATION', 'HOMEIMPROVEMENT', 'MEDICAL', 'PERSONAL', 'VENTURE']\n",
      "Loan Status = 1 Values: [1294, 967, 820, 1418, 961, 728]\n",
      "Loan Status = 0 Values: [3253, 4703, 2367, 3851, 3898, 4241]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:54956\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556d4ca5a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing data for the Bar Chart\n",
    "# Calculating the counts for each loan intent category for each loan status\n",
    "intent_counts = df.groupby(['loan_intent', 'loan_status']).size().unstack(fill_value=0)\n",
    "\n",
    "# Printing the calculated values for verification\n",
    "categories = intent_counts.index.tolist()\n",
    "status_1_values = intent_counts[1].tolist()\n",
    "status_0_values = intent_counts[0].tolist()\n",
    "\n",
    "print(\"Loan Intent Categories:\", categories)\n",
    "print(\"Loan Status = 1 Values:\", status_1_values)\n",
    "print(\"Loan Status = 0 Values:\", status_0_values)\n",
    "\n",
    "# Setting up the LightningChart environment\n",
    "chart = lc.BarChart(vertical=True)\n",
    "chart.set_title(\"Loan Intent by Status\")\n",
    "\n",
    "# Preparing grouped data\n",
    "grouped_data = [\n",
    "    {'name': 'Loan Status = Default', 'values': status_1_values},\n",
    "    {'name': 'Loan Status = Non-default', 'values': status_0_values}\n",
    "]\n",
    "\n",
    "# Setting grouped data on the chart\n",
    "chart.set_data_grouped(\n",
    "    categories,  \n",
    "    [\n",
    "        {'subCategory': grouped_data[0]['name'], 'values': grouped_data[0]['values']},\n",
    "        {'subCategory': grouped_data[1]['name'], 'values': grouped_data[1]['values']}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Adding a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(chart)  \n",
    "\n",
    "# Opening the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmenting 'person_income' into categorized groups for easier analysis\n",
    "df['income_group'] = pd.cut(df['person_income'],\n",
    "                            bins=[0, 25000, 50000, 75000, 100000, float('inf')],\n",
    "                            labels=['low', 'low-middle', 'middle', 'high-middle', 'high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 28501\n",
      "Variables: 13\n",
      "cat_cols: 6\n",
      "num_cols: 7\n",
      "cat_but_car: 0\n",
      "num_but_cat: 2\n"
     ]
    }
   ],
   "source": [
    "# Copying the original DataFrame to preserve the original data.\n",
    "dfx=df.copy()\n",
    "\n",
    "# Identifying categorical columns, categorical columns with many unique values, and numerical columns.\n",
    "cat_cols, cat_but_car, num_cols = grab_col_names(dfx)\n",
    "\n",
    "# Removing 'loan_status' from the list of categorical columns to prevent it from being encoded.\n",
    "cat_cols.remove(\"loan_status\")\n",
    "\n",
    "\n",
    "def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first,dtype=int)\n",
    "    return dataframe\n",
    "\n",
    "# Converting categorical variables into dummy/indicator variables\n",
    "dfx = one_hot_encoder(dfx, cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing 'X' by dropping 'loan_rate' and setting 'y' by isolating the 'loan_status' column\n",
    "X = dfx.drop(['loan_status',\"person_age\",\"person_income\"], axis=1)\n",
    "y = dfx['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28501, 24)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuring a preprocessing pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('constant',DropConstantFeatures()),\n",
    "    ('correlated',DropCorrelatedFeatures()),\n",
    "    ('duplicate',DropDuplicateFeatures())\n",
    "])\n",
    "\n",
    "X = pipeline.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dimensions of target label classes: Counter({1: 22313, 0: 22313})\n"
     ]
    }
   ],
   "source": [
    "# Initializing the BorderlineSMOTE method to handle class imbalance\n",
    "smote = BorderlineSMOTE()\n",
    "X, y = smote.fit_resample(X, y)\n",
    "print(\"Final dimensions of target label classes:\", Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42,stratify=y)\n",
    "#scaling variables\n",
    "scaler = StandardScaler()\n",
    "#scaler= RobustScaler()\n",
    "scaled_train_X = scaler.fit_transform(X_train)\n",
    "scaled_test_X = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for CatBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      4496\n",
      "           1       0.98      0.92      0.95      4430\n",
      "\n",
      "    accuracy                           0.95      8926\n",
      "   macro avg       0.95      0.95      0.95      8926\n",
      "weighted avg       0.95      0.95      0.95      8926\n",
      "\n",
      "Classification Report for LightGBM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      4496\n",
      "           1       0.98      0.91      0.94      4430\n",
      "\n",
      "    accuracy                           0.94      8926\n",
      "   macro avg       0.95      0.94      0.94      8926\n",
      "weighted avg       0.95      0.94      0.94      8926\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      4496\n",
      "           1       0.97      0.91      0.94      4430\n",
      "\n",
      "    accuracy                           0.94      8926\n",
      "   macro avg       0.94      0.94      0.94      8926\n",
      "weighted avg       0.94      0.94      0.94      8926\n",
      "\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      4496\n",
      "           1       0.98      0.92      0.95      4430\n",
      "\n",
      "    accuracy                           0.95      8926\n",
      "   macro avg       0.95      0.95      0.95      8926\n",
      "weighted avg       0.95      0.95      0.95      8926\n",
      "\n",
      "Classification Report for Stacking Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      4496\n",
      "           1       0.98      0.92      0.95      4430\n",
      "\n",
      "    accuracy                           0.95      8926\n",
      "   macro avg       0.95      0.95      0.95      8926\n",
      "weighted avg       0.95      0.95      0.95      8926\n",
      "\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score   ROC-AUC\n",
      "0             CatBoost  0.950370   0.952715  0.950113  0.950283  0.950113\n",
      "1             LightGBM  0.944096   0.946613  0.943827  0.943991  0.943827\n",
      "2        Random Forest  0.940735   0.942152  0.940534  0.940666  0.940534\n",
      "3              XGBoost  0.948689   0.950755  0.948448  0.948608  0.948448\n",
      "4  Stacking Classifier  0.950146   0.951692  0.949938  0.950084  0.949938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:11:33] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:11:34] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:11:34] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:11:34] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:11:34] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:11:34] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:11:34] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:11:35] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating a model\n",
    "def train_and_evaluate_model(model, model_name, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Collecting metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    roc_auc = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Printing classification report for debugging\n",
    "    print(f\"Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    }\n",
    "\n",
    "# Assuming 'X' and 'y' are already defined elsewhere in the code\n",
    "results = []\n",
    "results.append(train_and_evaluate_model(CatBoostClassifier(silent=True), \"CatBoost\", X, y))\n",
    "results.append(train_and_evaluate_model(LGBMClassifier(verbose=-1), \"LightGBM\", X, y))\n",
    "results.append(train_and_evaluate_model(RandomForestClassifier(), \"Random Forest\", X, y))\n",
    "results.append(train_and_evaluate_model(XGBClassifier(), \"XGBoost\", X, y))\n",
    "results.append(train_and_evaluate_model(StackingClassifier(estimators=[\n",
    "    ('ET', ExtraTreesClassifier()),\n",
    "    ('XGB', XGBClassifier()),\n",
    "    ('CAT', CatBoostClassifier(silent=True))\n",
    "], final_estimator=RandomForestClassifier(), verbose=2), \"Stacking Classifier\", X, y))\n",
    "\n",
    "# Converting results to DataFrame for display and analysis\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:55067\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556e97cef0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:25:53] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Preparing data for the Grouped Bar Chart\n",
    "# Initializing the BarChart from LightningChart\n",
    "chart = lc.BarChart(vertical=True, theme=lc.Themes.White, title='Grouped Model Performance Metrics')\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC']\n",
    "categories = [result['Model'] for result in results]\n",
    "\n",
    "data_grouped = [\n",
    "    {'subCategory': metric, 'values': [result[metric] for result in results]}\n",
    "    for metric in metrics\n",
    "]\n",
    "\n",
    "# Setting the grouped data for the bar chart\n",
    "chart.set_data_grouped(categories, data_grouped)\n",
    "\n",
    "# Adding a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(chart)\n",
    "\n",
    "# Displaying the chart\n",
    "chart.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:55077\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556e97ddc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:28:00] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Preparing data for the Bar Chart\n",
    "# Assuming 'X' and 'y' are already defined and preprocessed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting the model\n",
    "model = CatBoostClassifier(silent=True)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Getting feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Creating a DataFrame for easier handling\n",
    "feature_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "\n",
    "# Setting up the LightningChart environment\n",
    "chart = lc.BarChart(vertical=True, theme=lc.Themes.White, title=\"Feature Importances\")\n",
    "chart.set_data([{'category': row['Feature'], 'value': row['Importance']} for index, row in feature_df.iterrows()])\n",
    "\n",
    "# Adding sorting \n",
    "chart.set_sorting('descending')\n",
    "\n",
    "# Adding a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(chart)\n",
    "\n",
    "# Open the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Original Dataset Prediction:----------\n",
      "\n",
      "------------------------------------------------\n",
      "   person_age  person_income loan_intent  loan_amnt  loan_int_rate  Predictions\n",
      "0          22          59000    PERSONAL      35000          16.02      Default\n",
      "1          21           9600   EDUCATION       1000          11.14  Non-Default\n",
      "2          25           9600     MEDICAL       5500          12.87      Default\n",
      "3          23          65500     MEDICAL      35000          15.23      Default\n",
      "4          24          54400     MEDICAL      35000          14.27      Default\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Original Dataset Prediction\n",
    "# Adjusting display settings for DataFrame output\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Loading the data\n",
    "data = pd.read_csv(\"./credit_risk_dataset.csv\")\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Categorical and numerical columns are correctly defined\n",
    "cat_cols = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
    "num_cols = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income']\n",
    "\n",
    "# Encoding categorical data & creating 'income_group'\n",
    "data['income_group'] = pd.cut(data['person_income'],\n",
    "                            bins=[0, 25000, 50000, 75000, 100000, float('inf')],\n",
    "                            labels=['low', 'low-middle', 'middle', 'high-middle', 'high'])\n",
    "cat_cols.append('income_group')  \n",
    "\n",
    "data_encoded = pd.get_dummies(data, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "data_encoded[num_cols] = scaler.fit_transform(data_encoded[num_cols])\n",
    "\n",
    "# Splitting data into features and target\n",
    "X = data_encoded.drop('loan_status', axis=1)\n",
    "y = data_encoded['loan_status']\n",
    "\n",
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Defining and training the CatBoost model\n",
    "best_model = CatBoostClassifier(silent=True)\n",
    "best_model.fit(X_train, y_train)  \n",
    "\n",
    "# Loading new data to make predictions\n",
    "new_data = pd.read_csv(\"./credit_risk_dataset.csv\")\n",
    "new_data.drop_duplicates(inplace=True)\n",
    "new_data.dropna(inplace=True)\n",
    "\n",
    "# Processing new_data as done with the original data\n",
    "new_data['income_group'] = pd.cut(new_data['person_income'],\n",
    "                                bins=[0, 25000, 50000, 75000, 100000, float('inf')],\n",
    "                                labels=['low', 'low-middle', 'middle', 'high-middle', 'high'])\n",
    "new_data_encoded = pd.get_dummies(new_data, columns=cat_cols, drop_first=True)\n",
    "new_data_encoded[num_cols] = scaler.transform(new_data_encoded[num_cols]) \n",
    "\n",
    "# Aligning new data columns with the training features\n",
    "missing_cols = set(X.columns) - set(new_data_encoded.columns)\n",
    "for c in missing_cols:\n",
    "    new_data_encoded[c] = 0\n",
    "new_data_encoded = new_data_encoded[X.columns]  \n",
    "\n",
    "# Predicting using the trained model\n",
    "predictions = best_model.predict(new_data_encoded)\n",
    "new_data['Predictions'] = predictions\n",
    "\n",
    "# Mapping predictions for clarity\n",
    "new_data['Predictions'] = new_data['Predictions'].map({0: 'Non-Default', 1: 'Default'})\n",
    "\n",
    "# Displaying or saving the updated dataset with predictions\n",
    "print(\"\\n----------Original Dataset Prediction:----------\")\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(new_data[['person_age', 'person_income', 'loan_intent', 'loan_amnt', 'loan_int_rate', 'Predictions']].head())\n",
    "print(\"\\n------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------New Dataset Prediction:----------\n",
      "\n",
      "------------------------------------------------\n",
      "   person_age  person_income        loan_intent  loan_amnt  loan_int_rate  Predictions\n",
      "1          26          26004    HOMEIMPROVEMENT      10000          11.14  Non-Default\n",
      "2          23          33600           PERSONAL       1000          10.36  Non-Default\n",
      "3          25          33600  DEBTCONSOLIDATION       1000          11.86  Non-Default\n",
      "4          23          34000            MEDICAL       1000           7.37  Non-Default\n",
      "5          23          34800            VENTURE       1000          11.99  Non-Default\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# New Dataset Prediction\n",
    "# Adjusting display settings for DataFrame output\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Loading the data\n",
    "data = pd.read_csv(\"./dataset_for_prediction.csv\")\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Categorical and numerical columns are correctly defined\n",
    "cat_cols = ['person_home_ownership', 'loan_intent', 'cb_person_default_on_file']\n",
    "num_cols = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income']\n",
    "\n",
    "# Encoding categorical data & creating 'income_group'\n",
    "data['income_group'] = pd.cut(data['person_income'],\n",
    "                            bins=[0, 25000, 50000, 75000, 100000, float('inf')],\n",
    "                            labels=['low', 'low-middle', 'middle', 'high-middle', 'high'])\n",
    "cat_cols.append('income_group')  \n",
    "\n",
    "data_encoded = pd.get_dummies(data, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "data_encoded[num_cols] = scaler.fit_transform(data_encoded[num_cols])\n",
    "\n",
    "# Splitting data into features and target\n",
    "X = data_encoded.drop('loan_status', axis=1)\n",
    "y = data_encoded['loan_status']\n",
    "\n",
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Defining and training the CatBoost model\n",
    "best_model = CatBoostClassifier(silent=True)\n",
    "best_model.fit(X_train, y_train)  \n",
    "\n",
    "# Loading new data to make predictions\n",
    "new_data = pd.read_csv(\"./dataset_for_prediction.csv\")\n",
    "new_data.drop_duplicates(inplace=True)\n",
    "new_data.dropna(inplace=True)\n",
    "\n",
    "# Processing new_data as done with the original data\n",
    "new_data['income_group'] = pd.cut(new_data['person_income'],\n",
    "                                bins=[0, 25000, 50000, 75000, 100000, float('inf')],\n",
    "                                labels=['low', 'low-middle', 'middle', 'high-middle', 'high'])\n",
    "new_data_encoded = pd.get_dummies(new_data, columns=cat_cols, drop_first=True)\n",
    "new_data_encoded[num_cols] = scaler.transform(new_data_encoded[num_cols]) \n",
    "\n",
    "# Aligning new data columns with the training features\n",
    "missing_cols = set(X.columns) - set(new_data_encoded.columns)\n",
    "for c in missing_cols:\n",
    "    new_data_encoded[c] = 0\n",
    "new_data_encoded = new_data_encoded[X.columns]  \n",
    "\n",
    "# Predicting using the trained model\n",
    "predictions = best_model.predict(new_data_encoded)\n",
    "new_data['Predictions'] = predictions\n",
    "\n",
    "# Mapping predictions for clarity\n",
    "new_data['Predictions'] = new_data['Predictions'].map({0: 'Non-Default', 1: 'Default'})\n",
    "\n",
    "# Displaying or saving the updated dataset with predictions\n",
    "print(\"\\n----------New Dataset Prediction:----------\")\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(new_data[['person_age', 'person_income', 'loan_intent', 'loan_amnt', 'loan_int_rate', 'Predictions']].head())\n",
    "print(\"\\n------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Counts:\n",
      "loan_status\n",
      "Non-Default    22313\n",
      "Default         6188\n",
      "Sum ---------> 28501\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Original Dataset Prediction:\n",
      "Non-Default    4756\n",
      "Default         945\n",
      "Sum ---------> 5701\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "New Dataset Prediction:\n",
      "Non-Default    17139\n",
      "Default         2923\n",
      "Sum ---------> 20062\n"
     ]
    }
   ],
   "source": [
    "# Predictions and statistics\n",
    "# Loading the data\n",
    "data = pd.read_csv(\"./credit_risk_dataset.csv\")\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Mapping loan status directly in the original data for clarity\n",
    "data['loan_status'] = data['loan_status'].map({0: 'Non-Default', 1: 'Default'})\n",
    "\n",
    "# Original loan status count\n",
    "original_status_counts = data['loan_status'].value_counts()\n",
    "print(\"Original Dataset Counts:\")\n",
    "print(original_status_counts.to_string())\n",
    "print(\"Sum --------->\", original_status_counts.sum())\n",
    "\n",
    "# Defining categorical and numerical columns\n",
    "base_cat_cols = ['person_home_ownership', 'loan_intent', 'cb_person_default_on_file']\n",
    "num_cols = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income']\n",
    "\n",
    "# Adding 'loan_grade' if it exists in the dataset\n",
    "if 'loan_grade' in data.columns:\n",
    "    base_cat_cols.append('loan_grade')\n",
    "\n",
    "# Creating 'income_group'\n",
    "data['income_group'] = pd.cut(data['person_income'],\n",
    "                            bins=[0, 25000, 50000, 75000, 100000, float('inf')],\n",
    "                            labels=['low', 'low-middle', 'middle', 'high-middle', 'high'])\n",
    "base_cat_cols.append('income_group')\n",
    "\n",
    "data_encoded = pd.get_dummies(data, columns=base_cat_cols, drop_first=True)\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "data_encoded[num_cols] = scaler.fit_transform(data_encoded[num_cols])\n",
    "\n",
    "# Splitting data into features and target\n",
    "X = data_encoded.drop('loan_status', axis=1)\n",
    "y = data_encoded['loan_status']\n",
    "\n",
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Defining and training the CatBoost model\n",
    "best_model = CatBoostClassifier(silent=True)\n",
    "best_model.fit(X_train, y_train) \n",
    "\n",
    "# Predicting using the trained model on both datasets\n",
    "original_predictions = best_model.predict(X_test)\n",
    "new_data = pd.read_csv(\"./dataset_for_prediction.csv\")\n",
    "new_data.drop_duplicates(inplace=True)\n",
    "new_data.dropna(inplace=True)\n",
    "\n",
    "# Processing new_data as done with the original data\n",
    "new_data['income_group'] = pd.cut(new_data['person_income'],\n",
    "                                bins=[0, 25000, 50000, 75000, 100000, float('inf')],\n",
    "                                labels=['low', 'low-middle', 'middle', 'high-middle', 'high'])\n",
    "new_cat_cols = [col for col in base_cat_cols if col in new_data.columns]\n",
    "\n",
    "new_data_encoded = pd.get_dummies(new_data, columns=new_cat_cols, drop_first=True)\n",
    "new_data_encoded[num_cols] = scaler.transform(new_data_encoded[num_cols])  \n",
    "\n",
    "# Aligning new data columns with the training features\n",
    "missing_cols = set(X.columns) - set(new_data_encoded.columns)\n",
    "for c in missing_cols:\n",
    "    new_data_encoded[c] = 0\n",
    "new_data_encoded = new_data_encoded[X.columns]  \n",
    "\n",
    "new_predictions = best_model.predict(new_data_encoded)\n",
    "\n",
    "# Counting predictions\n",
    "original_prediction_counts = pd.Series(original_predictions).value_counts()\n",
    "new_prediction_counts = pd.Series(new_predictions).value_counts()\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"\\nOriginal Dataset Prediction:\")\n",
    "print(original_prediction_counts.to_string())\n",
    "print(\"Sum --------->\", original_prediction_counts.sum())\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"\\nNew Dataset Prediction:\")\n",
    "print(new_prediction_counts.to_string())\n",
    "print(\"Sum --------->\", new_prediction_counts.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:55199\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556e3c6c90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:13:00] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Preparing data for the Bar Chart\n",
    "# Converting prediction counts to int for JSON serialization\n",
    "original_non_default_status_count = int(original_status_counts.get('Non-Default', 0))\n",
    "original_default_status_count = int(original_status_counts.get('Default', 0))\n",
    "original_non_default_count = int(original_prediction_counts.get('Non-Default', 0))\n",
    "original_default_count = int(original_prediction_counts.get('Default', 0))\n",
    "new_non_default_count = int(new_prediction_counts.get('Non-Default', 0))\n",
    "new_default_count = int(new_prediction_counts.get('Default', 0))\n",
    "\n",
    "# Initializing the chart\n",
    "chart = lc.BarChart(vertical=True, theme=lc.Themes.White, title='Credit Risk Predictions Comparison')\n",
    "\n",
    "# Configuring the data for the chart, ensuring values are native Python integers\n",
    "chart.set_data_grouped(\n",
    "    ['1. Original Dataset Count', '2. Original Dataset Prediction', '3. New Dataset Prediction'],\n",
    "    [\n",
    "        {'subCategory': 'Non-Default', 'values': [ original_non_default_status_count, original_non_default_count, new_non_default_count]},\n",
    "        {'subCategory': 'Default', 'values': [original_default_status_count, original_default_count, new_default_count]}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Sorting the chart\n",
    "chart.set_sorting('alphabetical')\n",
    "\n",
    "# Adding a legend to the chart\n",
    "legend = chart.add_legend().add(chart)\n",
    "\n",
    "# Opening the chart\n",
    "chart.open() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:55200\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1556e3c59d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jun/2024 12:13:00] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Preparing data for the Box Plot\n",
    "# Converting prediction counts to int for JSON serialization\n",
    "original_non_default_status_count = int(original_status_counts.get('Non-Default', 0))\n",
    "original_default_status_count = int(original_status_counts.get('Default', 0))\n",
    "original_non_default_count = int(original_prediction_counts.get('Non-Default', 0))\n",
    "original_default_count = int(original_prediction_counts.get('Default', 0))\n",
    "new_non_default_count = int(new_prediction_counts.get('Non-Default', 0))\n",
    "new_default_count = int(new_prediction_counts.get('Default', 0))\n",
    "\n",
    "# Simulating multiple data points around the main counts\n",
    "def generate_data_around_count(count, num_points=10, spread=1000):\n",
    "    return [count + random.randint(-spread, spread) for _ in range(num_points)]\n",
    "\n",
    "data = [\n",
    "    generate_data_around_count(original_non_default_status_count),\n",
    "    generate_data_around_count(original_default_status_count),\n",
    "    generate_data_around_count(original_non_default_count),\n",
    "    generate_data_around_count(new_non_default_count),\n",
    "    generate_data_around_count(original_default_count),\n",
    "    generate_data_around_count(new_default_count)\n",
    "]\n",
    "\n",
    "# Initializing the chart\n",
    "chart = lc.BoxPlot(\n",
    "    data=data,\n",
    "    theme=lc.Themes.White,\n",
    "    title='Credit Risk Predictions Comparison',\n",
    "    xlabel='Categories',\n",
    "    ylabel='Counts'\n",
    ")\n",
    "\n",
    "# Opening the chart\n",
    "chart.open()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
